---
title: "Modern Data Processing"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Notes 13: Modern Data Processing}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(Rdlazer)
mtcars. <- head(mtcars, 10)
```


<br><br><br>


There have been considerable efforts in the R community to change the way data is handled. They were driven by different motivations and utilized different approaches. We will briefly introduce two major branches of developlement.


<br><br><br>


## The Tidyverse

The Tidyverse is a large enterprise with a comprehensive underlying philosophy. It consists a large (and growing) number of packages that deal with various aspects of R, including (meta)programming. That is beyond our interests here, we will stick to data processing. Just keep in mind that some parts of the Tidyverse were there before it was called that and they can work somewhat independently.

Tidyverse packages can be installed and attached jointly as if they were one package called `tidyverse` but they can also be treated separately, as usual.

As far as data processing goes, fll functions have a consistent syntax, they all return a (modified) copy of the data and they all use non standard evaluation to save the user some typing. All names, logical predicates, and operations are evaluated within the scope of the data frame in question. The first argument is always the data frame to be modified.

<br>

#### tidy data

There is an argument to be made that keeping various data sets in a consistent format facilitates more efficient work as a lot of the time spent on data analysis involves cleaning up data and bringing it to a desired format. Thus the concept of "tidy" data emerged and was popularized by Hadley Wickham, the main driving force behind the Tidyverse. This is where the name comes from, by the way.
[Read more if you wish.](https://www.jstatsoft.org/article/view/v059i10)

Briefly, tidy data is kept in long format rather than wide. 
```{r}
wide <- data.frame(men = c(175, 187, 168), 
                   women = c(158, 166, 166))
long <- data.frame(sex = rep(c('men', 'women'), each = 3),
                   height = c(175, 187, 168, 158, 166, 166))

wide

long
```
Each measurement occupies one and only one column. If observations can be divided into groups/categories, the category information should be stored in additional variables (columns).

<br>

#### manipulating data with `dplyr`

```{r}
library(dplyr)
```

`dplyr` is a package for data frame operations. It arose from an effort to streamline working with data frames and to add some functionalities to the data structure.

1. Looking at data

- `glimpse` provides a better view of the contents of the data frame than `str`
- `glimpse` also returns the unchanged data invisibly
- additionally, data frames are converted to different classes with different `print` methods
```{r}
glimpse(mtcars)
```

<br>

2. Renaming columns

- `rename` gives new names to columns as if new columns were assigned within the data frame
- the renamed columns can be specified by name or position
```{r}
rename(iris, SL = Sepal.Length)

rename(iris, SL = 1)
```

<br>

2. Subsetting columns

- columns are selected with the `select` function
- columns can be specified by name or by position
- a range of columns can be specified with the `:` operator
- columns are dropped with `-`
- there also a set of very useful "select helper" functions, which includes:
    - `matches` selects columns whose names match a regular expression
    - `one_of` selects columns whose names are elements of a character vectors
    - `everything` selects all columns not selected before
```{r}
select(mtcars., make, model)

select(mtcars., 1:4)

select(mtcars., make : disp)

select(mtcars., -1, -2)

select(mtcars., matches('^m'))

select(mtcars., mpg, cyl, everything())
```

- the selected columns can be given new names on the fly
```{r}
select(iris, Sepal.Length, SL = Sepal.Length, species = Species)
```

<br>

3. Subsetting rows

- rows are selected with `filter` or `slice`
- `slice` specifies rows by numeric indices
```{r}
slice(iris, 1:3)
```
- `filter` uses logical vectors or predicates that can be evaluated within the data to produce logical vectors
- unlike in `subset`, multiple vectors can be passed, separated by commas, rather than a single logical predicate, so there is no need to use `&`
```{r}
filter(iris, Species == 'setosa')

filter(iris, Species == 'versicolor', Sepal.Width < 3)
```

<br>

4. Selecting random rows

- `sample_n` randomly selects a given number of rows
- `sample_frac` randomly selects a fraction of rows
```{r}
sample_n(iris, 5)

sample_n(iris, 0.2)
```

<br>

5. Sorting data

- sorting is done with `arrange`
- pass one or more columns on which to sort the data
- ties in the first column are broken by values of the second, etc.
- use the `desc` function to arrange in descending order
```{r}
arrange(iris, Sepal.Length, Sepal.Width)

arrange(iris, desc(Sepal.Length), Sepal.Width)
```

<br>

6. Adding columns

- new columns are created with `mutate` or `transmute`
- syntax is as if assigning new variables within the data
- several assignments can be made ina single `mutate` call, separated by commas
- operations can use column created earlier in the same `mutate` call
- use names of existing columns for rowwise calculations
- external variables can also be used
- `transmute` does the same but only returns the new column(s)
```{r}
mutate(iris, Sepal.Area = Sepal.Length * Sepal.Width)

mutate(iris, new_column  = 'text')

mutate(iris, Sepal.Area = Sepal.Length * Sepal.Width, 
       message = paste0('the sepal area is ', Sepal.Area))

transmute(iris, Sepal.Area = Sepal.Length * Sepal.Width,
          message = paste0('the sepal area is ', Sepal.Area))
```

<br>

7. Computing summary statistics

- `summarize` is used to compute on columns
- syntax is much like mutate but it collapses the data to a single row and drops non-relevant columns
```{r}
summarize(iris, mSL = mean(Sepal.Length))
```

<br>

8. Grouping observations

- data can be split into subsets so that subsequent operations are done on parts of data separately
- the `group_by` function takes one or more columns (grouping variables) and splits observations into groups by combinations of values of those variables
- this is `dplyr`'s implementation of the split-apply-combine paradigm
```{r}
iris.g <- group_by(iris, Species)
summarize(iris.g, mSL = mean(Sepal.Length))

slice(iris.g, 1:2)

mtcars.g <- group_by(mtcars, cyl, gear, carb)
summarize(mtcars.g, m.disp = mean(disp))
```

<br>

#### other `dplyr` functions

The `do` function can be used to perform any operation within a data frame. This is used when mutate is insufficient because the desired result is not a vector but a different structure, e.g. a data frame or a model (class `lm`, for instance). `do` produces **list columns**. List columnas are a native feature of data frames. They are lists rather than atomic vectors. They are very rarely used.

Some `plyr` functions have "scoped" variants that allow for simultaneous operations on multiple columns. For example, `mutate_at` performs the same operations on columns specified by name or position, `mutate_if` operates on columns specified by a logical predicate, and `mutate_all` acts on all columns. The problem with `dplyr`, and the tidyverse in general, is that their usage is constantly evolving and difficult to keep track of for non-users. We will not discuss them in detail, they are well documented in the help files and online.

The `n` function returns the number of rows of the data frame in which it is called.
`count` and `tally` report on the numbers of observations in groups in grouped data frames.


<br><br><br>


#### reshaping data with `tidyr`

Switching between wide and long format is a frequent operation. One reason is it is often easier to collect data in wide form. Another reason is preparing data for plotting and adjusting the shape of the data to a particular plotting function. The Tidyverse solutions for rehsaping data are implemented in the `tidyr` package. 
```{r}
library(tidyr)
```

The most common operations are wide-long conversion and combining and splitting text columns. We will use a small data set for demonstration.

```{r}
i <- slice(iris.g, 1:2)
```

1. wide to long format conversion with `gather`

- the values of several columns are wrapped into one
- a new column must be created to tell which data point comes from which old column
- specify the `key` column - this is where the names of old columns go
- specify the `value` column - this is where the values of old columns end up
- then specify the columns to be wrapped together
- pass column names as you would to `select`, including using select helpers
```{r}
(ig1 <- gather(i, key = sepal.part, value = size, matches('Sepal')))

(ig2 <- gather(i, key = flower.part, value = size, -Species))
```

<br>

2. long to wide format conversion with `spread`

- `spread` does the reverse of `gather`
- one column is converted into several
- specify the `key` column, which contains category information - these will be the names of new columns
- specify the `value` column, where contains values that will be distributed between the new columns
```{r}
spread(ig1, sepal.part, size)
```
- long to wide conversion can (and will) fail if it is impossible to assign unique identity to observations
```{r, error = TRUE}
spread(ig2, flower.part, size)
```
- this can be avoided by adding an additional column with unique values
```{r}
(i <- mutate(i, id = 1:n()))

(ig2 <- gather(i, key = flower.part, value = size, -id, -Species))

spread(ig2, flower.part, size)
```
- note that `n()` in `mutate` was called to groups, not the whole data frame

<br>

3. combining columns with `unite`

- `combine` provides a way of potting two columns together like pasting two or more vectors
- non-character columns are coerced to character
- specify the new column name first and then the columns to combine
- olg columns can be kept or dropped with the `remove` argument
```{r}
(iu <- unite(i, new_column, Sepal.Length, Sepal.Width, sep = '__'))
```

<br>

4. splitting columns with `separate`

- `separate` does the reverse of `unite`
- specify the column to be split and names of new columns - the latter must be given as a character vector, no NSE this time
- you must specify a regex on which the strings will be split
- like in `unite` the old column can be kept or dropped with `remove`
- new columns can be converted to numeric (if appropriate) with `convert`
```{r}
separate(iu, new_column, c('sl', 'sw'), sep = '__', convert = TRUE)
```


<br><br><br>


#### streaming operations

The Tidyverse encourages a heavy use of **piping** expressions. This is done with the **pipe** operator (`%>%`) incorporated from the `magrittr` package. The way a pipe works is it is placed between two expressions, takes the **value** of the LHS expression and passes it as an **argument** to the RHS expression. By default the value is matched positionally to the first formal argument of the function on the RHS. This can be overriden using a dummy: the LHS value will be passed to the argument specified as `.`.
```{r}
rnorm(1e+4) %>% round(3) %>% summary
```

Annonymous functions can also be used.
```{r}
set.seed(0)
rnorm(1e+4) %>% round(3) %>% (function(x) which(x == 0))
```

Breaking lines after pipes can make for neat code.
```{r}
'*#&$_-+=' %>% 
  strsplit(split = '') %>% 
  .[[1]] %>% sample(1) %>% 
  paste(' ', ' ', sep = .) %>% 
  paste(letters[1:5], collapse = .)
```

Piping can be used in any situation but tidyverse functions are epecifically created with this mechanic in mind. This is why every returns a modified copy of the original data, which can then be immediately pipied into another function call.

```{r}
iris %>% 
  group_by(Species) %>%
  summarize_at(.vars = 1:4, .funs = list(mean = mean, error = sd)) %>%
  arrange(desc(Petal.Length_error))
```


<br><br><br>


*to be continued...*

